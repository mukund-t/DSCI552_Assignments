{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyy1DRPtecI0"
   },
   "source": [
    "### Name: Mukund Tamizharasan\n",
    "### USC ID: 7355725345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cV4NrqxYemM4",
    "outputId": "662770c8-f689-470d-eba8-f8a8cd4b52a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUEhjde8fJZr",
    "outputId": "eedcc462-0e24-4bbd-8bdb-aa7a28ad34ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/DSCI552_HW7\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/MyDrive/DSCI552_HW7/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rquQAFtFecI2"
   },
   "source": [
    "# Generative Models for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "nxOZ1KoVecI2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Mn-KtJzihx04"
   },
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (c) i. Concatenate your text files to create a corpus of Russell’s writings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "zNWNko21ecI3"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for book in os.listdir(\"./books/\"):\n",
    "    f = open(\"./books/\"+book, 'r', errors='ignore',encoding = \"ascii\")\n",
    "    text = f.read()\n",
    "    text = text.replace(\"\\n\",\"\")\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^A-Za-z0-9 ,.]+', '', text)\n",
    "    corpus.append(text)\n",
    "\n",
    "corpus = sorted(corpus, key=lambda x : len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (c) ii. Use a character-level representation for this model by using extended ASCII that has N = 256 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "4ceFCgUQecI3"
   },
   "outputs": [],
   "source": [
    "full_text = ''\n",
    "for text in corpus[:4]:\n",
    "    full_text+=text\n",
    "chars = list(set(full_text))\n",
    "\n",
    "chars2ascii = {char:ord(char) for char in chars}\n",
    "ascii2chars = {ord(char):char for char in chars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6mMg-PgecI4",
    "outputId": "df11b3dd-4ef2-4df3-f700-82bb39212ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 110, '5': 53, '6': 54, 'h': 104, '4': 52, 'w': 119, 'a': 97, 'l': 108, 'j': 106, 'u': 117, 'y': 121, 'f': 102, 'v': 118, '8': 56, '7': 55, 'x': 120, 'z': 122, ',': 44, '3': 51, '9': 57, 'm': 109, 'b': 98, 'g': 103, 'o': 111, '.': 46, 't': 116, ' ': 32, 'c': 99, 'q': 113, '1': 49, 'e': 101, 'p': 112, 'i': 105, 'd': 100, '0': 48, 's': 115, '2': 50, 'r': 114, 'k': 107}\n"
     ]
    }
   ],
   "source": [
    "print(chars2ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (c) iii. Choose a window size, e.g., W = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNHwi2mgecI4",
    "outputId": "56f4ceaf-b767-4ea0-c122-368a3187ca0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of corpus: 1536315\n"
     ]
    }
   ],
   "source": [
    "W = 100\n",
    "\n",
    "print(\"Length of corpus:\", len(full_text))\n",
    "n = max(chars2ascii.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (c) iv. Inputs to the network will be the first W −1 = 99 characters of each sequence, and the output of the network will be the Wth character of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "lUX1bWE1ecI5"
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(len(full_text)-W+1):\n",
    "    temp = []\n",
    "    for j in range(W-1):\n",
    "        temp.append(chars2ascii[full_text[i+j]]/n)\n",
    "    x.append(temp)\n",
    "    y.append(chars2ascii[full_text[i+j+1]])\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (c) v. Note that the output has to be encoded using a one-hot encoding scheme with N = 256 (or less) elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSJ5pACuecI5",
    "outputId": "332cb9f8-fb28-4655-a906-d9478ffa93c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536216, 123)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh = to_categorical(y)\n",
    "y_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIyCrJ-decI6",
    "outputId": "bec46786-5e50-4dbe-f730-802629065098"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536216, 99)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVSIdSvYecI6",
    "outputId": "55e77a01-cfb9-4ef7-80b5-aaaefc34f8e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536216, 99, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.reshape(1536216, 99, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (c) vi. Use a single hidden layer for the LSTM with N = 256 (or less) memory units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eC4wuaMfecI6",
    "outputId": "04e6b040-a838-417a-a930-76a014b21d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 256)               264192    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 123)               31611     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 295,803\n",
      "Trainable params: 295,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# References:\n",
    "# https://www.analyticsvidhya.com/blog/2021/06/lstm-for-text-classification/\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(x.shape[1],x.shape[2]), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(123,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4FjYfPlyetE"
   },
   "source": [
    "### 1. (c) x. Use model checkpointing to keep the network weights to determine each time an improvement in loss is observed at the end of the epoch. Find the best set of weights in terms of loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vd5ickjAecI7",
    "outputId": "8891c518-2cc4-445c-f763-45db32b0e7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 57467301888.0000 - accuracy: 0.0857\n",
      "Epoch 00001: loss improved from inf to 57467301888.00000, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 337s 442ms/step - loss: 57467301888.0000 - accuracy: 0.0857\n",
      "Epoch 2/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 845721.9375 - accuracy: 0.1514\n",
      "Epoch 00002: loss improved from 57467301888.00000 to 845721.93750, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 330s 435ms/step - loss: 845721.9375 - accuracy: 0.1514\n",
      "Epoch 3/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.9611 - accuracy: 0.1603\n",
      "Epoch 00003: loss improved from 845721.93750 to 2.96106, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 330s 435ms/step - loss: 2.9611 - accuracy: 0.1603\n",
      "Epoch 4/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.9592 - accuracy: 0.1603\n",
      "Epoch 00004: loss improved from 2.96106 to 2.95920, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 332s 438ms/step - loss: 2.9592 - accuracy: 0.1603\n",
      "Epoch 5/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.9578 - accuracy: 0.1603\n",
      "Epoch 00005: loss improved from 2.95920 to 2.95783, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 335s 442ms/step - loss: 2.9578 - accuracy: 0.1603\n",
      "Epoch 6/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.9562 - accuracy: 0.1603\n",
      "Epoch 00006: loss improved from 2.95783 to 2.95618, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 331s 436ms/step - loss: 2.9562 - accuracy: 0.1603\n",
      "Epoch 7/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.9504 - accuracy: 0.1607\n",
      "Epoch 00007: loss improved from 2.95618 to 2.95040, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 327s 431ms/step - loss: 2.9504 - accuracy: 0.1607\n",
      "Epoch 8/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8672 - accuracy: 0.1839\n",
      "Epoch 00008: loss improved from 2.95040 to 2.86720, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 327s 431ms/step - loss: 2.8672 - accuracy: 0.1839\n",
      "Epoch 9/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8348 - accuracy: 0.1891\n",
      "Epoch 00009: loss improved from 2.86720 to 2.83483, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 326s 430ms/step - loss: 2.8348 - accuracy: 0.1891\n",
      "Epoch 10/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8217 - accuracy: 0.1927\n",
      "Epoch 00010: loss improved from 2.83483 to 2.82169, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 329s 434ms/step - loss: 2.8217 - accuracy: 0.1927\n",
      "Epoch 11/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8141 - accuracy: 0.1947\n",
      "Epoch 00011: loss improved from 2.82169 to 2.81412, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 327s 431ms/step - loss: 2.8141 - accuracy: 0.1947\n",
      "Epoch 12/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8057 - accuracy: 0.1971\n",
      "Epoch 00012: loss improved from 2.81412 to 2.80574, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 328s 432ms/step - loss: 2.8057 - accuracy: 0.1971\n",
      "Epoch 13/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.7945 - accuracy: 0.1998\n",
      "Epoch 00013: loss improved from 2.80574 to 2.79453, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 328s 433ms/step - loss: 2.7945 - accuracy: 0.1998\n",
      "Epoch 14/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.7836 - accuracy: 0.2028\n",
      "Epoch 00014: loss improved from 2.79453 to 2.78358, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 331s 437ms/step - loss: 2.7836 - accuracy: 0.2028\n",
      "Epoch 15/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.7748 - accuracy: 0.2054\n",
      "Epoch 00015: loss improved from 2.78358 to 2.77485, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 328s 433ms/step - loss: 2.7748 - accuracy: 0.2054\n",
      "Epoch 16/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.7666 - accuracy: 0.2075\n",
      "Epoch 00016: loss improved from 2.77485 to 2.76657, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 328s 432ms/step - loss: 2.7666 - accuracy: 0.2075\n",
      "Epoch 17/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8351 - accuracy: 0.1968\n",
      "Epoch 00017: loss did not improve from 2.76657\n",
      "758/758 [==============================] - 326s 430ms/step - loss: 2.8351 - accuracy: 0.1968\n",
      "Epoch 18/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8356 - accuracy: 0.1920\n",
      "Epoch 00018: loss did not improve from 2.76657\n",
      "758/758 [==============================] - 326s 430ms/step - loss: 2.8356 - accuracy: 0.1920\n",
      "Epoch 19/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.7830 - accuracy: 0.2045\n",
      "Epoch 00019: loss did not improve from 2.76657\n",
      "758/758 [==============================] - 327s 431ms/step - loss: 2.7830 - accuracy: 0.2045\n",
      "Epoch 20/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.7655 - accuracy: 0.2084\n",
      "Epoch 00020: loss improved from 2.76657 to 2.76551, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 325s 429ms/step - loss: 2.7655 - accuracy: 0.2084\n",
      "Epoch 21/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.7605 - accuracy: 0.2098\n",
      "Epoch 00021: loss improved from 2.76551 to 2.76050, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 322s 425ms/step - loss: 2.7605 - accuracy: 0.2098\n",
      "Epoch 22/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.7565 - accuracy: 0.2110\n",
      "Epoch 00022: loss improved from 2.76050 to 2.75648, saving model to ./best_weights_lstm.h5\n",
      "758/758 [==============================] - 324s 427ms/step - loss: 2.7565 - accuracy: 0.2110\n",
      "Epoch 23/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8372 - accuracy: 0.1904\n",
      "Epoch 00023: loss did not improve from 2.75648\n",
      "758/758 [==============================] - 326s 430ms/step - loss: 2.8372 - accuracy: 0.1904\n",
      "Epoch 24/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8422 - accuracy: 0.1873\n",
      "Epoch 00024: loss did not improve from 2.75648\n",
      "758/758 [==============================] - 329s 434ms/step - loss: 2.8422 - accuracy: 0.1873\n",
      "Epoch 25/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8289 - accuracy: 0.1908\n",
      "Epoch 00025: loss did not improve from 2.75648\n",
      "758/758 [==============================] - 330s 435ms/step - loss: 2.8289 - accuracy: 0.1908\n",
      "Epoch 26/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8213 - accuracy: 0.1921\n",
      "Epoch 00026: loss did not improve from 2.75648\n",
      "758/758 [==============================] - 325s 429ms/step - loss: 2.8213 - accuracy: 0.1921\n",
      "Epoch 27/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8162 - accuracy: 0.1933\n",
      "Epoch 00027: loss did not improve from 2.75648\n",
      "758/758 [==============================] - 324s 428ms/step - loss: 2.8162 - accuracy: 0.1933\n",
      "Epoch 28/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8225 - accuracy: 0.1920\n",
      "Epoch 00028: loss did not improve from 2.75648\n",
      "758/758 [==============================] - 325s 428ms/step - loss: 2.8225 - accuracy: 0.1920\n",
      "Epoch 29/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8113 - accuracy: 0.1942\n",
      "Epoch 00029: loss did not improve from 2.75648\n",
      "758/758 [==============================] - 326s 430ms/step - loss: 2.8113 - accuracy: 0.1942\n",
      "Epoch 30/30\n",
      "758/758 [==============================] - ETA: 0s - loss: 2.8070 - accuracy: 0.1947\n",
      "Epoch 00030: loss did not improve from 2.75648\n",
      "758/758 [==============================] - 328s 432ms/step - loss: 2.8070 - accuracy: 0.1947\n"
     ]
    }
   ],
   "source": [
    "callback = [ModelCheckpoint(filepath='./best_weights_lstm.h5',monitor=\"loss\",verbose=1,save_best_only=True, save_freq=\"epoch\"), ]\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x, y_oh, batch_size=512, epochs=30, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjjA18MOhK1J",
    "outputId": "f1a7089c-89c5-4eab-f721-eb2cd076b5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"./best_weights_lstm.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (c) xi. Use the network with the best weights to generate 1000 characters, using the following text as initialization of the network:\n",
    "\n",
    "There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "TmsnAguRJl2z"
   },
   "outputs": [],
   "source": [
    "test_text = \"There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.\"\n",
    "\n",
    "test_textenc = [chars2ascii[i] for i in test_text[-99:].lower()]\n",
    "test_textenc = np.array(test_textenc)\n",
    "test_textenc = test_textenc.reshape(1,99,1)\n",
    "\n",
    "char_keys=list(ascii2chars.keys())\n",
    "\n",
    "for i in range(1000):\n",
    "  pred = list(model.predict(test_textenc)[0])\n",
    "  pred_ = [[pred[i],i] for i in range(len(pred))]\n",
    "  pred_ = sorted(pred_,key=lambda x: x[0],reverse=True)\n",
    "  char =''\n",
    "  for i in pred_:\n",
    "    if i[1] in char_keys:\n",
    "      char = i[1]\n",
    "      break\n",
    "  test_text+=ascii2chars[char]\n",
    "  temp = list(test_textenc.reshape(1,99)[0])\n",
    "  temp.append(char)\n",
    "  temp = np.array(temp[1:])\n",
    "  test_textenc = temp.reshape(1,99,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "fdfqd8twcfon",
    "outputId": "eab84eba-d8e9-42cc-d873-a766a9d1e98a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.6 v7   gm     z5     m pche c am  w  q a      2 z  5m     ek   3 m 4  53e  e   0   o  z l  .   4 g3q gl7  ze  5 heg jq     6m  56  4qhg      z6z  6ee y  y  kzqq z  m  h 6 gn bhehm64 e k  6e      v. mq   j 3 ohm 2  bqc 6cztq 5  coqe5y56v 1h c 5gmbkz  g6   zm 3 9   6je5 e tk v  pb z5zl z    4  e  zzj7ec 6 ot  meqz9o3 m   z.6z j   g   qd m e2  6u m    46 e et   3 z93  8  e0p2z vqg     zgt g1lm    ma6e c  cw    17e 6mh  e  z  q  w j  m z s  54bme   . u w 7c  g z3 0t6o6y  p 7 m  6 o t  wq3 6  66   pc z 5 q23  q  j  t   g   8  5w   m7  z          mq   e  3r  e g pht6 z   em6m zl. v  5 3   e1 5ew  m      z     6 e 7m   z  6 47z 4z o z    j 5 z  g u   v g vt z c zez3b    4azp e  z         b46 52mc e v   m omtbz  g  6a  q5m   65g cmtk zm  c     k 3 e6zz 5 czt   z.   mz   t  6m t  e 6m   ta h5z4cotgh2vg96 p   mzj       2gv  jmh9 5g 6 l7 2 g  cz5h  3jmb5 23wbk   p    6 yc e z 7656   j m7  qeyt 5cq hm mt eh tg  ge583      8tmp z h azok, k6cmt  ztqo3   h    m 4 c  o    3w5   4u j ch9h   e zmpgm em '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEiqrQOo-rxJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HW7_LSTM_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
