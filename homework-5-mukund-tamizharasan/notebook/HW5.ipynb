{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Mukund Tamizharasan\n",
    "### USC ID: 7355725345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024017</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083536</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.554504</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.443451</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.021860</td>\n",
       "      <td>-0.079860</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517273</td>\n",
       "      <td>-0.370574</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.402890</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.101892</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.582557</td>\n",
       "      <td>-0.343237</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.385596</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.080425</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.519497</td>\n",
       "      <td>-0.307553</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>-0.096895</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508833</td>\n",
       "      <td>-0.324106</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>0.058874</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>0.072983</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.087910</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1          1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2          1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3          1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4          1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7190       1.0 -0.554504 -0.337717  0.035533  0.034511  0.443451  0.093889   \n",
       "7191       1.0 -0.517273 -0.370574  0.030673  0.068097  0.402890  0.096628   \n",
       "7192       1.0 -0.582557 -0.343237  0.029468  0.064179  0.385596  0.114905   \n",
       "7193       1.0 -0.519497 -0.307553 -0.004922  0.072865  0.377131  0.086866   \n",
       "7194       1.0 -0.508833 -0.324106  0.062068  0.078211  0.397188  0.094596   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_16  MFCCs_17  MFCCs_18  \\\n",
       "0    -0.150063 -0.171128  0.124676  ... -0.024017 -0.108351 -0.077623   \n",
       "1    -0.222475 -0.207693  0.170883  ...  0.012022 -0.090974 -0.056510   \n",
       "2    -0.242234 -0.219153  0.232538  ...  0.083536 -0.050691 -0.023590   \n",
       "3    -0.194347 -0.098181  0.270375  ... -0.050224 -0.136009 -0.177037   \n",
       "4    -0.265423 -0.172700  0.266434  ...  0.062837 -0.048885 -0.053074   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7190 -0.100753  0.037087  0.081075  ... -0.000861  0.069430  0.071001   \n",
       "7191 -0.116460  0.063727  0.089034  ...  0.006457  0.061127  0.068978   \n",
       "7192 -0.103317  0.070370  0.081317  ...  0.008696  0.082474  0.077771   \n",
       "7193 -0.115799  0.056979  0.089316  ...  0.001924  0.051796  0.069073   \n",
       "7194 -0.117672  0.058874  0.076180  ...  0.004158  0.061455  0.072983   \n",
       "\n",
       "      MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus  \\\n",
       "0    -0.009568  0.057684  0.118680  0.014038  Leptodactylidae  Adenomera   \n",
       "1    -0.035303  0.020140  0.082263  0.029056  Leptodactylidae  Adenomera   \n",
       "2    -0.066722 -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera   \n",
       "3    -0.130498 -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera   \n",
       "4    -0.088550 -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera   \n",
       "...        ...       ...       ...       ...              ...        ...   \n",
       "7190  0.021591  0.052449 -0.021860 -0.079860          Hylidae     Scinax   \n",
       "7191  0.017745  0.046461 -0.015418 -0.101892          Hylidae     Scinax   \n",
       "7192 -0.009688  0.027834 -0.000531 -0.080425          Hylidae     Scinax   \n",
       "7193  0.017963  0.041803 -0.027911 -0.096895          Hylidae     Scinax   \n",
       "7194 -0.003980  0.031560 -0.029355 -0.087910          Hylidae     Scinax   \n",
       "\n",
       "             Species  \n",
       "0     AdenomeraAndre  \n",
       "1     AdenomeraAndre  \n",
       "2     AdenomeraAndre  \n",
       "3     AdenomeraAndre  \n",
       "4     AdenomeraAndre  \n",
       "...              ...  \n",
       "7190     ScinaxRuber  \n",
       "7191     ScinaxRuber  \n",
       "7192     ScinaxRuber  \n",
       "7193     ScinaxRuber  \n",
       "7194     ScinaxRuber  \n",
       "\n",
       "[7195 rows x 25 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Frogs_MFCCs.csv\")\n",
    "del df[\"RecordID\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_true = test_set.iloc[:,-3:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (b) i. Research exact match and hamming score/ loss methods for evaluating multi- label classification and use them in evaluating the classifiers in this problem.\n",
    "\n",
    "Exact match ratio is the ratio of all the predicted labels that match the true labels.\n",
    "Hamming loss it the total number of predicted labels that do not match the true label divided by the product of number of labels and number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(y_true, y_pred):\n",
    "    #hamming loss\n",
    "    cnt=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        for j in range(y_true.shape[1]):\n",
    "            if y_true[i,j]!=y_pred[i,j]:\n",
    "                cnt+=1\n",
    "    hamming_loss = (1/(y_true.shape[0]*y_true.shape[1]))*cnt\n",
    "    \n",
    "    #exact match ratio\n",
    "    cnt=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if all(y_true[i] == y_pred[i]):\n",
    "            cnt+=1\n",
    "    exact_match_ratio = cnt / y_true.shape[0]\n",
    "    \n",
    "    print(\"Hamming Loss: \",hamming_loss)\n",
    "    print(\"Exact Match Ratio: \",exact_match_ratio)\n",
    "    \n",
    "    return {\"hamming_loss\":hamming_loss,\"exact_match_ratio\":exact_match_ratio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (b) ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# references \n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "def best_params(xtrain,ytrain,params,estimator,scoring,cv):\n",
    "    clf = GridSearchCV(estimator=estimator, param_grid=params, scoring=scoring, n_jobs=-1, cv=cv, verbose=2)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    cv_res = clf.cv_results_\n",
    "    for i in range(len(cv_res['params'])):\n",
    "        print(cv_res['params'][i],\" gives mean test score of \", cv_res['mean_test_score'][i])\n",
    "        \n",
    "    print(\"Best score is \",clf.best_score_,\" for parameters \",clf.best_params_)\n",
    "                                                                                          \n",
    "    return clf                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Family Label\n",
    "\n",
    "family_train = train_set\n",
    "family_train = family_train.drop(columns=['Genus','Species'])\n",
    "family_test = test_set\n",
    "family_test = family_test.drop(columns=['Genus','Species'])\n",
    "\n",
    "family_xtrain, family_ytrain = family_train.iloc[:,:-1].to_numpy(), family_train.iloc[:,-1].to_numpy()\n",
    "family_xtest, family_ytest = family_test.iloc[:,:-1].to_numpy(), family_test.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, gamma=0.1)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovr', kernel='rbf', C=0.1, gamma=0.1)\n",
    "clf.fit(family_xtrain, family_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8854249404289118"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(family_xtrain,family_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "Results:\n",
      "{'C': 0.1, 'gamma': 0.1}  gives mean test score of  0.868673139416216\n",
      "{'C': 0.1, 'gamma': 0.2}  gives mean test score of  0.9196710306347746\n",
      "{'C': 0.1, 'gamma': 0.30000000000000004}  gives mean test score of  0.9353689803716152\n",
      "{'C': 0.1, 'gamma': 0.4}  gives mean test score of  0.9406411361220128\n",
      "{'C': 0.1, 'gamma': 0.5}  gives mean test score of  0.9444227779772059\n",
      "{'C': 0.1, 'gamma': 0.6}  gives mean test score of  0.9477253187347445\n",
      "{'C': 0.1, 'gamma': 0.7000000000000001}  gives mean test score of  0.9506530848215077\n",
      "{'C': 0.1, 'gamma': 0.8}  gives mean test score of  0.9532150076429344\n",
      "{'C': 0.1, 'gamma': 0.9}  gives mean test score of  0.9555640822945832\n",
      "{'C': 0.1, 'gamma': 1.0}  gives mean test score of  0.9567240158109026\n",
      "{'C': 1, 'gamma': 0.1}  gives mean test score of  0.9392789455502568\n",
      "{'C': 1, 'gamma': 0.2}  gives mean test score of  0.9545637207167648\n",
      "{'C': 1, 'gamma': 0.30000000000000004}  gives mean test score of  0.9608983788690161\n",
      "{'C': 1, 'gamma': 0.4}  gives mean test score of  0.9662582234573118\n",
      "{'C': 1, 'gamma': 0.5}  gives mean test score of  0.968434678588938\n",
      "{'C': 1, 'gamma': 0.6}  gives mean test score of  0.9733980793200463\n",
      "{'C': 1, 'gamma': 0.7000000000000001}  gives mean test score of  0.9812921833913405\n",
      "{'C': 1, 'gamma': 0.8}  gives mean test score of  0.9839640745974254\n",
      "{'C': 1, 'gamma': 0.9}  gives mean test score of  0.9853778855257949\n",
      "{'C': 1, 'gamma': 1.0}  gives mean test score of  0.986206389778659\n",
      "{'C': 10, 'gamma': 0.1}  gives mean test score of  0.965415663662643\n",
      "{'C': 10, 'gamma': 0.2}  gives mean test score of  0.9824347636006451\n",
      "{'C': 10, 'gamma': 0.30000000000000004}  gives mean test score of  0.9842448747827405\n",
      "{'C': 10, 'gamma': 0.4}  gives mean test score of  0.9860288700903844\n",
      "{'C': 10, 'gamma': 0.5}  gives mean test score of  0.9872182662618363\n",
      "{'C': 10, 'gamma': 0.6}  gives mean test score of  0.9882139370056857\n",
      "{'C': 10, 'gamma': 0.7000000000000001}  gives mean test score of  0.9891900685286104\n",
      "{'C': 10, 'gamma': 0.8}  gives mean test score of  0.9903807004572498\n",
      "{'C': 10, 'gamma': 0.9}  gives mean test score of  0.9907792145866704\n",
      "{'C': 10, 'gamma': 1.0}  gives mean test score of  0.9905812811232858\n",
      "{'C': 100, 'gamma': 0.1}  gives mean test score of  0.9841264397217386\n",
      "{'C': 100, 'gamma': 0.2}  gives mean test score of  0.9866443155178837\n",
      "{'C': 100, 'gamma': 0.30000000000000004}  gives mean test score of  0.9890296499890681\n",
      "{'C': 100, 'gamma': 0.4}  gives mean test score of  0.9890360944389422\n",
      "{'C': 100, 'gamma': 0.5}  gives mean test score of  0.9898311365898893\n",
      "{'C': 100, 'gamma': 0.6}  gives mean test score of  0.9908056747596676\n",
      "{'C': 100, 'gamma': 0.7000000000000001}  gives mean test score of  0.9912084876831285\n",
      "{'C': 100, 'gamma': 0.8}  gives mean test score of  0.9913877977108487\n",
      "{'C': 100, 'gamma': 0.9}  gives mean test score of  0.9917823419906062\n",
      "{'C': 100, 'gamma': 1.0}  gives mean test score of  0.9919765619820968\n",
      "{'C': 1000, 'gamma': 0.1}  gives mean test score of  0.9868339915781392\n",
      "{'C': 1000, 'gamma': 0.2}  gives mean test score of  0.9882386709530457\n",
      "{'C': 1000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9890562080880457\n",
      "{'C': 1000, 'gamma': 0.4}  gives mean test score of  0.989040963753116\n",
      "{'C': 1000, 'gamma': 0.5}  gives mean test score of  0.9902221311603192\n",
      "{'C': 1000, 'gamma': 0.6}  gives mean test score of  0.9910179051650637\n",
      "{'C': 1000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9908090339502378\n",
      "{'C': 1000, 'gamma': 0.8}  gives mean test score of  0.9915834369489328\n",
      "{'C': 1000, 'gamma': 0.9}  gives mean test score of  0.9915834369489328\n",
      "{'C': 1000, 'gamma': 1.0}  gives mean test score of  0.991780669895698\n",
      "{'C': 10000, 'gamma': 0.1}  gives mean test score of  0.987637127321908\n",
      "{'C': 10000, 'gamma': 0.2}  gives mean test score of  0.9878598144056635\n",
      "{'C': 10000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9890415946061937\n",
      "{'C': 10000, 'gamma': 0.4}  gives mean test score of  0.989040963753116\n",
      "{'C': 10000, 'gamma': 0.5}  gives mean test score of  0.9902221311603192\n",
      "{'C': 10000, 'gamma': 0.6}  gives mean test score of  0.9910179051650637\n",
      "{'C': 10000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9908090339502378\n",
      "{'C': 10000, 'gamma': 0.8}  gives mean test score of  0.9915834369489328\n",
      "{'C': 10000, 'gamma': 0.9}  gives mean test score of  0.9915834369489328\n",
      "{'C': 10000, 'gamma': 1.0}  gives mean test score of  0.991780669895698\n",
      "{'C': 100000, 'gamma': 0.1}  gives mean test score of  0.9868396578004027\n",
      "{'C': 100000, 'gamma': 0.2}  gives mean test score of  0.9878598144056635\n",
      "{'C': 100000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9890415946061937\n",
      "{'C': 100000, 'gamma': 0.4}  gives mean test score of  0.989040963753116\n",
      "{'C': 100000, 'gamma': 0.5}  gives mean test score of  0.9902221311603192\n",
      "{'C': 100000, 'gamma': 0.6}  gives mean test score of  0.9910179051650637\n",
      "{'C': 100000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9908090339502378\n",
      "{'C': 100000, 'gamma': 0.8}  gives mean test score of  0.9915834369489328\n",
      "{'C': 100000, 'gamma': 0.9}  gives mean test score of  0.9915834369489328\n",
      "{'C': 100000, 'gamma': 1.0}  gives mean test score of  0.991780669895698\n",
      "{'C': 1000000, 'gamma': 0.1}  gives mean test score of  0.9868396578004027\n",
      "{'C': 1000000, 'gamma': 0.2}  gives mean test score of  0.9878598144056635\n",
      "{'C': 1000000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9890415946061937\n",
      "{'C': 1000000, 'gamma': 0.4}  gives mean test score of  0.989040963753116\n",
      "{'C': 1000000, 'gamma': 0.5}  gives mean test score of  0.9902221311603192\n",
      "{'C': 1000000, 'gamma': 0.6}  gives mean test score of  0.9910179051650637\n",
      "{'C': 1000000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9908090339502378\n",
      "{'C': 1000000, 'gamma': 0.8}  gives mean test score of  0.9915834369489328\n",
      "{'C': 1000000, 'gamma': 0.9}  gives mean test score of  0.9915834369489328\n",
      "{'C': 1000000, 'gamma': 1.0}  gives mean test score of  0.991780669895698\n",
      "Best score is  0.9919765619820968  for parameters  {'C': 100, 'gamma': 1.0}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-1,7)]\n",
    "gamma_list = np.arange(0.1,1.1,0.1)\n",
    "params = {\"C\":C_list,\"gamma\":gamma_list}\n",
    "\n",
    "estimator = svm.SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "clf = best_params(family_xtrain,family_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_pred = clf.predict(family_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genus Label\n",
    "\n",
    "genus_train = train_set\n",
    "genus_train = genus_train.drop(columns=['Family','Species'])\n",
    "genus_test = test_set\n",
    "genus_test = genus_test.drop(columns=['Family','Species'])\n",
    "\n",
    "genus_xtrain, genus_ytrain = genus_train.iloc[:,:-1].to_numpy(), genus_train.iloc[:,-1].to_numpy()\n",
    "genus_xtest, genus_ytest = genus_test.iloc[:,:-1].to_numpy(), genus_test.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "Results:\n",
      "{'C': 0.1, 'gamma': 0.1}  gives mean test score of  0.7680102689170887\n",
      "{'C': 0.1, 'gamma': 0.2}  gives mean test score of  0.8432699003314763\n",
      "{'C': 0.1, 'gamma': 0.30000000000000004}  gives mean test score of  0.8567512840581116\n",
      "{'C': 0.1, 'gamma': 0.4}  gives mean test score of  0.8856318089421304\n",
      "{'C': 0.1, 'gamma': 0.5}  gives mean test score of  0.9008352356533653\n",
      "{'C': 0.1, 'gamma': 0.6}  gives mean test score of  0.9060913592467713\n",
      "{'C': 0.1, 'gamma': 0.7000000000000001}  gives mean test score of  0.910671761409429\n",
      "{'C': 0.1, 'gamma': 0.8}  gives mean test score of  0.9148756201884328\n",
      "{'C': 0.1, 'gamma': 0.9}  gives mean test score of  0.9185072969726417\n",
      "{'C': 0.1, 'gamma': 1.0}  gives mean test score of  0.9217456325598388\n",
      "{'C': 1, 'gamma': 0.1}  gives mean test score of  0.9201669253545612\n",
      "{'C': 1, 'gamma': 0.2}  gives mean test score of  0.941907212050354\n",
      "{'C': 1, 'gamma': 0.30000000000000004}  gives mean test score of  0.9598226297737146\n",
      "{'C': 1, 'gamma': 0.4}  gives mean test score of  0.9695632775808525\n",
      "{'C': 1, 'gamma': 0.5}  gives mean test score of  0.9729914825064527\n",
      "{'C': 1, 'gamma': 0.6}  gives mean test score of  0.976904138075456\n",
      "{'C': 1, 'gamma': 0.7000000000000001}  gives mean test score of  0.9794127889484228\n",
      "{'C': 1, 'gamma': 0.8}  gives mean test score of  0.9816729326386973\n",
      "{'C': 1, 'gamma': 0.9}  gives mean test score of  0.9841274974220207\n",
      "{'C': 1, 'gamma': 1.0}  gives mean test score of  0.9845163443825855\n",
      "{'C': 10, 'gamma': 0.1}  gives mean test score of  0.9744242535155319\n",
      "{'C': 10, 'gamma': 0.2}  gives mean test score of  0.9812390061767069\n",
      "{'C': 10, 'gamma': 0.30000000000000004}  gives mean test score of  0.9873109937147087\n",
      "{'C': 10, 'gamma': 0.4}  gives mean test score of  0.9879226340577765\n",
      "{'C': 10, 'gamma': 0.5}  gives mean test score of  0.988275845041968\n",
      "{'C': 10, 'gamma': 0.6}  gives mean test score of  0.9877370060672785\n",
      "{'C': 10, 'gamma': 0.7000000000000001}  gives mean test score of  0.9881696930051976\n",
      "{'C': 10, 'gamma': 0.8}  gives mean test score of  0.9885487768775795\n",
      "{'C': 10, 'gamma': 0.9}  gives mean test score of  0.9887592123535762\n",
      "{'C': 10, 'gamma': 1.0}  gives mean test score of  0.9887574776854366\n",
      "{'C': 100, 'gamma': 0.1}  gives mean test score of  0.9861231377946039\n",
      "{'C': 100, 'gamma': 0.2}  gives mean test score of  0.9881310507935359\n",
      "{'C': 100, 'gamma': 0.30000000000000004}  gives mean test score of  0.9885785576542936\n",
      "{'C': 100, 'gamma': 0.4}  gives mean test score of  0.9885843034511901\n",
      "{'C': 100, 'gamma': 0.5}  gives mean test score of  0.9887725673114554\n",
      "{'C': 100, 'gamma': 0.6}  gives mean test score of  0.9891872445814487\n",
      "{'C': 100, 'gamma': 0.7000000000000001}  gives mean test score of  0.9891872445814487\n",
      "{'C': 100, 'gamma': 0.8}  gives mean test score of  0.9895784366510032\n",
      "{'C': 100, 'gamma': 0.9}  gives mean test score of  0.9895776616298566\n",
      "{'C': 100, 'gamma': 1.0}  gives mean test score of  0.9895776616298566\n",
      "{'C': 1000, 'gamma': 0.1}  gives mean test score of  0.9859574750989271\n",
      "{'C': 1000, 'gamma': 0.2}  gives mean test score of  0.987150403159436\n",
      "{'C': 1000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9883503074414743\n",
      "{'C': 1000, 'gamma': 0.4}  gives mean test score of  0.9883589652278765\n",
      "{'C': 1000, 'gamma': 0.5}  gives mean test score of  0.9891673274956012\n",
      "{'C': 1000, 'gamma': 0.6}  gives mean test score of  0.9889651876572716\n",
      "{'C': 1000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9891623462865213\n",
      "{'C': 1000, 'gamma': 0.8}  gives mean test score of  0.9893625528685182\n",
      "{'C': 1000, 'gamma': 0.9}  gives mean test score of  0.9895776616298566\n",
      "{'C': 1000, 'gamma': 1.0}  gives mean test score of  0.9893731491973649\n",
      "{'C': 10000, 'gamma': 0.1}  gives mean test score of  0.9855505225761177\n",
      "{'C': 10000, 'gamma': 0.2}  gives mean test score of  0.9873407653206279\n",
      "{'C': 10000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9881502041800585\n",
      "{'C': 10000, 'gamma': 0.4}  gives mean test score of  0.9883589652278765\n",
      "{'C': 10000, 'gamma': 0.5}  gives mean test score of  0.9891673274956012\n",
      "{'C': 10000, 'gamma': 0.6}  gives mean test score of  0.9889651876572716\n",
      "{'C': 10000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9891623462865213\n",
      "{'C': 10000, 'gamma': 0.8}  gives mean test score of  0.9893625528685182\n",
      "{'C': 10000, 'gamma': 0.9}  gives mean test score of  0.9895776616298566\n",
      "{'C': 10000, 'gamma': 1.0}  gives mean test score of  0.9893731491973649\n",
      "{'C': 100000, 'gamma': 0.1}  gives mean test score of  0.9855505225761177\n",
      "{'C': 100000, 'gamma': 0.2}  gives mean test score of  0.9873407653206279\n",
      "{'C': 100000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9881502041800585\n",
      "{'C': 100000, 'gamma': 0.4}  gives mean test score of  0.9883589652278765\n",
      "{'C': 100000, 'gamma': 0.5}  gives mean test score of  0.9891673274956012\n",
      "{'C': 100000, 'gamma': 0.6}  gives mean test score of  0.9889651876572716\n",
      "{'C': 100000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9891623462865213\n",
      "{'C': 100000, 'gamma': 0.8}  gives mean test score of  0.9893625528685182\n",
      "{'C': 100000, 'gamma': 0.9}  gives mean test score of  0.9895776616298566\n",
      "{'C': 100000, 'gamma': 1.0}  gives mean test score of  0.9893731491973649\n",
      "{'C': 1000000, 'gamma': 0.1}  gives mean test score of  0.9855505225761177\n",
      "{'C': 1000000, 'gamma': 0.2}  gives mean test score of  0.9873407653206279\n",
      "{'C': 1000000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9881502041800585\n",
      "{'C': 1000000, 'gamma': 0.4}  gives mean test score of  0.9883589652278765\n",
      "{'C': 1000000, 'gamma': 0.5}  gives mean test score of  0.9891673274956012\n",
      "{'C': 1000000, 'gamma': 0.6}  gives mean test score of  0.9889651876572716\n",
      "{'C': 1000000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9891623462865213\n",
      "{'C': 1000000, 'gamma': 0.8}  gives mean test score of  0.9893625528685182\n",
      "{'C': 1000000, 'gamma': 0.9}  gives mean test score of  0.9895776616298566\n",
      "{'C': 1000000, 'gamma': 1.0}  gives mean test score of  0.9893731491973649\n",
      "Best score is  0.9895784366510032  for parameters  {'C': 100, 'gamma': 0.8}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-1,7)]\n",
    "gamma_list = np.arange(0.1,1.1,0.1)\n",
    "params = {\"C\":C_list,\"gamma\":gamma_list}\n",
    "\n",
    "estimator = svm.SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "clf = best_params(genus_xtrain,genus_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_pred = clf.predict(genus_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Species Label\n",
    "\n",
    "species_train = train_set\n",
    "species_train = species_train.drop(columns=['Family','Genus'])\n",
    "species_test = test_set\n",
    "species_test = species_test.drop(columns=['Family','Genus'])\n",
    "\n",
    "species_xtrain, species_ytrain = species_train.iloc[:,:-1].to_numpy(), species_train.iloc[:,-1].to_numpy()\n",
    "species_xtest, species_ytest = species_test.iloc[:,:-1].to_numpy(), species_test.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "Results:\n",
      "{'C': 0.1, 'gamma': 0.1}  gives mean test score of  0.7882765336309369\n",
      "{'C': 0.1, 'gamma': 0.2}  gives mean test score of  0.853164434516262\n",
      "{'C': 0.1, 'gamma': 0.30000000000000004}  gives mean test score of  0.8862454500381698\n",
      "{'C': 0.1, 'gamma': 0.4}  gives mean test score of  0.900891425838276\n",
      "{'C': 0.1, 'gamma': 0.5}  gives mean test score of  0.9084030552187276\n",
      "{'C': 0.1, 'gamma': 0.6}  gives mean test score of  0.9121080103426562\n",
      "{'C': 0.1, 'gamma': 0.7000000000000001}  gives mean test score of  0.9151822066814399\n",
      "{'C': 0.1, 'gamma': 0.8}  gives mean test score of  0.918445168174082\n",
      "{'C': 0.1, 'gamma': 0.9}  gives mean test score of  0.9238803778223394\n",
      "{'C': 0.1, 'gamma': 1.0}  gives mean test score of  0.9280819602303966\n",
      "{'C': 1, 'gamma': 0.1}  gives mean test score of  0.9345708917094504\n",
      "{'C': 1, 'gamma': 0.2}  gives mean test score of  0.9596331534550699\n",
      "{'C': 1, 'gamma': 0.30000000000000004}  gives mean test score of  0.9672371717912214\n",
      "{'C': 1, 'gamma': 0.4}  gives mean test score of  0.971859503320806\n",
      "{'C': 1, 'gamma': 0.5}  gives mean test score of  0.9768397705716383\n",
      "{'C': 1, 'gamma': 0.6}  gives mean test score of  0.9791387036748734\n",
      "{'C': 1, 'gamma': 0.7000000000000001}  gives mean test score of  0.9808006616809628\n",
      "{'C': 1, 'gamma': 0.8}  gives mean test score of  0.9829086848037566\n",
      "{'C': 1, 'gamma': 0.9}  gives mean test score of  0.9837322493861516\n",
      "{'C': 1, 'gamma': 1.0}  gives mean test score of  0.9859584090267255\n",
      "{'C': 10, 'gamma': 0.1}  gives mean test score of  0.9776252471659564\n",
      "{'C': 10, 'gamma': 0.2}  gives mean test score of  0.9847604978818403\n",
      "{'C': 10, 'gamma': 0.30000000000000004}  gives mean test score of  0.9857744942114739\n",
      "{'C': 10, 'gamma': 0.4}  gives mean test score of  0.9871616703602942\n",
      "{'C': 10, 'gamma': 0.5}  gives mean test score of  0.9877804485811772\n",
      "{'C': 10, 'gamma': 0.6}  gives mean test score of  0.988586829722081\n",
      "{'C': 10, 'gamma': 0.7000000000000001}  gives mean test score of  0.9879879094953194\n",
      "{'C': 10, 'gamma': 0.8}  gives mean test score of  0.9881805975809543\n",
      "{'C': 10, 'gamma': 0.9}  gives mean test score of  0.9887865519613614\n",
      "{'C': 10, 'gamma': 1.0}  gives mean test score of  0.9889995465307242\n",
      "{'C': 100, 'gamma': 0.1}  gives mean test score of  0.9866231382907369\n",
      "{'C': 100, 'gamma': 0.2}  gives mean test score of  0.9864300872425652\n",
      "{'C': 100, 'gamma': 0.30000000000000004}  gives mean test score of  0.987637385426955\n",
      "{'C': 100, 'gamma': 0.4}  gives mean test score of  0.9878481876657952\n",
      "{'C': 100, 'gamma': 0.5}  gives mean test score of  0.9878599516297948\n",
      "{'C': 100, 'gamma': 0.6}  gives mean test score of  0.9882512656522886\n",
      "{'C': 100, 'gamma': 0.7000000000000001}  gives mean test score of  0.9884446806645784\n",
      "{'C': 100, 'gamma': 0.8}  gives mean test score of  0.9882368064136294\n",
      "{'C': 100, 'gamma': 0.9}  gives mean test score of  0.988436074594264\n",
      "{'C': 100, 'gamma': 1.0}  gives mean test score of  0.9884467387736325\n",
      "{'C': 1000, 'gamma': 0.1}  gives mean test score of  0.9863031932047648\n",
      "{'C': 1000, 'gamma': 0.2}  gives mean test score of  0.9874960730249469\n",
      "{'C': 1000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9872522504226243\n",
      "{'C': 1000, 'gamma': 0.4}  gives mean test score of  0.9876381967180162\n",
      "{'C': 1000, 'gamma': 0.5}  gives mean test score of  0.9878398578985823\n",
      "{'C': 1000, 'gamma': 0.6}  gives mean test score of  0.9878457635104093\n",
      "{'C': 1000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9880465290110905\n",
      "{'C': 1000, 'gamma': 0.8}  gives mean test score of  0.9884376192597972\n",
      "{'C': 1000, 'gamma': 0.9}  gives mean test score of  0.988436074594264\n",
      "{'C': 1000, 'gamma': 1.0}  gives mean test score of  0.9884467387736325\n",
      "{'C': 10000, 'gamma': 0.1}  gives mean test score of  0.9870813011146232\n",
      "{'C': 10000, 'gamma': 0.2}  gives mean test score of  0.9874960730249469\n",
      "{'C': 10000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9872522504226243\n",
      "{'C': 10000, 'gamma': 0.4}  gives mean test score of  0.9876381967180162\n",
      "{'C': 10000, 'gamma': 0.5}  gives mean test score of  0.9878398578985823\n",
      "{'C': 10000, 'gamma': 0.6}  gives mean test score of  0.9878457635104093\n",
      "{'C': 10000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9880465290110905\n",
      "{'C': 10000, 'gamma': 0.8}  gives mean test score of  0.9884376192597972\n",
      "{'C': 10000, 'gamma': 0.9}  gives mean test score of  0.988436074594264\n",
      "{'C': 10000, 'gamma': 1.0}  gives mean test score of  0.9884467387736325\n",
      "{'C': 100000, 'gamma': 0.1}  gives mean test score of  0.9870813011146232\n",
      "{'C': 100000, 'gamma': 0.2}  gives mean test score of  0.9874960730249469\n",
      "{'C': 100000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9872522504226243\n",
      "{'C': 100000, 'gamma': 0.4}  gives mean test score of  0.9876381967180162\n",
      "{'C': 100000, 'gamma': 0.5}  gives mean test score of  0.9878398578985823\n",
      "{'C': 100000, 'gamma': 0.6}  gives mean test score of  0.9878457635104093\n",
      "{'C': 100000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9880465290110905\n",
      "{'C': 100000, 'gamma': 0.8}  gives mean test score of  0.9884376192597972\n",
      "{'C': 100000, 'gamma': 0.9}  gives mean test score of  0.988436074594264\n",
      "{'C': 100000, 'gamma': 1.0}  gives mean test score of  0.9884467387736325\n",
      "{'C': 1000000, 'gamma': 0.1}  gives mean test score of  0.9870813011146232\n",
      "{'C': 1000000, 'gamma': 0.2}  gives mean test score of  0.9874960730249469\n",
      "{'C': 1000000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9872522504226243\n",
      "{'C': 1000000, 'gamma': 0.4}  gives mean test score of  0.9876381967180162\n",
      "{'C': 1000000, 'gamma': 0.5}  gives mean test score of  0.9878398578985823\n",
      "{'C': 1000000, 'gamma': 0.6}  gives mean test score of  0.9878457635104093\n",
      "{'C': 1000000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9880465290110905\n",
      "{'C': 1000000, 'gamma': 0.8}  gives mean test score of  0.9884376192597972\n",
      "{'C': 1000000, 'gamma': 0.9}  gives mean test score of  0.988436074594264\n",
      "{'C': 1000000, 'gamma': 1.0}  gives mean test score of  0.9884467387736325\n",
      "Best score is  0.9889995465307242  for parameters  {'C': 10, 'gamma': 1.0}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-1,7)]\n",
    "gamma_list = np.arange(0.1,1.1,0.1)\n",
    "params = {\"C\":C_list,\"gamma\":gamma_list}\n",
    "\n",
    "estimator = svm.SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "clf = best_params(species_xtrain,species_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_pred = clf.predict(species_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_pred = np.array([family_pred,genus_pred,species_pred]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss:  0.008491585610622202\n",
      "Exact Match Ratio:  0.9861046780917091\n"
     ]
    }
   ],
   "source": [
    "summary_dict[\"SVM_Gaussian_no_std\"] = eval_model(y_multi_true,y_multi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_set.iloc[:,:-3])\n",
    "\n",
    "sc_xtrain = scaler.transform(train_set.iloc[:,:-3])\n",
    "sc_xtest = scaler.transform(test_set.iloc[:,:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_xtrain, family_ytrain = sc_xtrain, train_set[\"Family\"].to_numpy()\n",
    "family_xtest, family_ytest = sc_xtest, test_set[\"Family\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "Results:\n",
      "{'C': 0.1, 'gamma': 0.1}  gives mean test score of  0.9676481020701507\n",
      "{'C': 0.1, 'gamma': 0.2}  gives mean test score of  0.972968382406143\n",
      "{'C': 0.1, 'gamma': 0.30000000000000004}  gives mean test score of  0.9664316763140359\n",
      "{'C': 0.1, 'gamma': 0.4}  gives mean test score of  0.9092609468319843\n",
      "{'C': 0.1, 'gamma': 0.5}  gives mean test score of  0.8568517298071286\n",
      "{'C': 0.1, 'gamma': 0.6}  gives mean test score of  0.8018064176676809\n",
      "{'C': 0.1, 'gamma': 0.7000000000000001}  gives mean test score of  0.7543943229280274\n",
      "{'C': 0.1, 'gamma': 0.8}  gives mean test score of  0.7173251563766844\n",
      "{'C': 0.1, 'gamma': 0.9}  gives mean test score of  0.6970664956074097\n",
      "{'C': 0.1, 'gamma': 1.0}  gives mean test score of  0.6825305406673648\n",
      "{'C': 1, 'gamma': 0.1}  gives mean test score of  0.9880027181864584\n",
      "{'C': 1, 'gamma': 0.2}  gives mean test score of  0.9844838519511697\n",
      "{'C': 1, 'gamma': 0.30000000000000004}  gives mean test score of  0.98096281582499\n",
      "{'C': 1, 'gamma': 0.4}  gives mean test score of  0.9766273916903\n",
      "{'C': 1, 'gamma': 0.5}  gives mean test score of  0.9714413402816268\n",
      "{'C': 1, 'gamma': 0.6}  gives mean test score of  0.9662848575436109\n",
      "{'C': 1, 'gamma': 0.7000000000000001}  gives mean test score of  0.9632832497137919\n",
      "{'C': 1, 'gamma': 0.8}  gives mean test score of  0.9628114999870011\n",
      "{'C': 1, 'gamma': 0.9}  gives mean test score of  0.9205945586886649\n",
      "{'C': 1, 'gamma': 1.0}  gives mean test score of  0.9016544307341426\n",
      "{'C': 10, 'gamma': 0.1}  gives mean test score of  0.9892046152073908\n",
      "{'C': 10, 'gamma': 0.2}  gives mean test score of  0.9850739872905023\n",
      "{'C': 10, 'gamma': 0.30000000000000004}  gives mean test score of  0.9819479366167908\n",
      "{'C': 10, 'gamma': 0.4}  gives mean test score of  0.97799973343558\n",
      "{'C': 10, 'gamma': 0.5}  gives mean test score of  0.9734265113342229\n",
      "{'C': 10, 'gamma': 0.6}  gives mean test score of  0.9675366708011806\n",
      "{'C': 10, 'gamma': 0.7000000000000001}  gives mean test score of  0.9644886035332837\n",
      "{'C': 10, 'gamma': 0.8}  gives mean test score of  0.9641338454238907\n",
      "{'C': 10, 'gamma': 0.9}  gives mean test score of  0.9266768291551838\n",
      "{'C': 10, 'gamma': 1.0}  gives mean test score of  0.9069087275332837\n",
      "{'C': 100, 'gamma': 0.1}  gives mean test score of  0.9894023086716416\n",
      "{'C': 100, 'gamma': 0.2}  gives mean test score of  0.9850739872905023\n",
      "{'C': 100, 'gamma': 0.30000000000000004}  gives mean test score of  0.9819479366167908\n",
      "{'C': 100, 'gamma': 0.4}  gives mean test score of  0.97799973343558\n",
      "{'C': 100, 'gamma': 0.5}  gives mean test score of  0.9734265113342229\n",
      "{'C': 100, 'gamma': 0.6}  gives mean test score of  0.9675366708011806\n",
      "{'C': 100, 'gamma': 0.7000000000000001}  gives mean test score of  0.9644886035332837\n",
      "{'C': 100, 'gamma': 0.8}  gives mean test score of  0.9641338454238907\n",
      "{'C': 100, 'gamma': 0.9}  gives mean test score of  0.9266768291551838\n",
      "{'C': 100, 'gamma': 1.0}  gives mean test score of  0.9069087275332837\n",
      "{'C': 1000, 'gamma': 0.1}  gives mean test score of  0.9894023086716416\n",
      "{'C': 1000, 'gamma': 0.2}  gives mean test score of  0.9850739872905023\n",
      "{'C': 1000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9819479366167908\n",
      "{'C': 1000, 'gamma': 0.4}  gives mean test score of  0.97799973343558\n",
      "{'C': 1000, 'gamma': 0.5}  gives mean test score of  0.9734265113342229\n",
      "{'C': 1000, 'gamma': 0.6}  gives mean test score of  0.9675366708011806\n",
      "{'C': 1000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9644886035332837\n",
      "{'C': 1000, 'gamma': 0.8}  gives mean test score of  0.9641338454238907\n",
      "{'C': 1000, 'gamma': 0.9}  gives mean test score of  0.9266768291551838\n",
      "{'C': 1000, 'gamma': 1.0}  gives mean test score of  0.9069087275332837\n",
      "{'C': 10000, 'gamma': 0.1}  gives mean test score of  0.9894023086716416\n",
      "{'C': 10000, 'gamma': 0.2}  gives mean test score of  0.9850739872905023\n",
      "{'C': 10000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9819479366167908\n",
      "{'C': 10000, 'gamma': 0.4}  gives mean test score of  0.97799973343558\n",
      "{'C': 10000, 'gamma': 0.5}  gives mean test score of  0.9734265113342229\n",
      "{'C': 10000, 'gamma': 0.6}  gives mean test score of  0.9675366708011806\n",
      "{'C': 10000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9644886035332837\n",
      "{'C': 10000, 'gamma': 0.8}  gives mean test score of  0.9641338454238907\n",
      "{'C': 10000, 'gamma': 0.9}  gives mean test score of  0.9266768291551838\n",
      "{'C': 10000, 'gamma': 1.0}  gives mean test score of  0.9069087275332837\n",
      "{'C': 100000, 'gamma': 0.1}  gives mean test score of  0.9894023086716416\n",
      "{'C': 100000, 'gamma': 0.2}  gives mean test score of  0.9850739872905023\n",
      "{'C': 100000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9819479366167908\n",
      "{'C': 100000, 'gamma': 0.4}  gives mean test score of  0.97799973343558\n",
      "{'C': 100000, 'gamma': 0.5}  gives mean test score of  0.9734265113342229\n",
      "{'C': 100000, 'gamma': 0.6}  gives mean test score of  0.9675366708011806\n",
      "{'C': 100000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9644886035332837\n",
      "{'C': 100000, 'gamma': 0.8}  gives mean test score of  0.9641338454238907\n",
      "{'C': 100000, 'gamma': 0.9}  gives mean test score of  0.9266768291551838\n",
      "{'C': 100000, 'gamma': 1.0}  gives mean test score of  0.9069087275332837\n",
      "{'C': 1000000, 'gamma': 0.1}  gives mean test score of  0.9894023086716416\n",
      "{'C': 1000000, 'gamma': 0.2}  gives mean test score of  0.9850739872905023\n",
      "{'C': 1000000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9819479366167908\n",
      "{'C': 1000000, 'gamma': 0.4}  gives mean test score of  0.97799973343558\n",
      "{'C': 1000000, 'gamma': 0.5}  gives mean test score of  0.9734265113342229\n",
      "{'C': 1000000, 'gamma': 0.6}  gives mean test score of  0.9675366708011806\n",
      "{'C': 1000000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9644886035332837\n",
      "{'C': 1000000, 'gamma': 0.8}  gives mean test score of  0.9641338454238907\n",
      "{'C': 1000000, 'gamma': 0.9}  gives mean test score of  0.9266768291551838\n",
      "{'C': 1000000, 'gamma': 1.0}  gives mean test score of  0.9069087275332837\n",
      "Best score is  0.9894023086716416  for parameters  {'C': 100, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-1,7)]\n",
    "gamma_list = np.arange(0.1,1.1,0.1)\n",
    "params = {\"C\":C_list,\"gamma\":gamma_list}\n",
    "\n",
    "estimator = svm.SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "clf = best_params(family_xtrain,family_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_pred = clf.predict(family_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_xtrain, genus_ytrain = sc_xtrain, train_set[\"Genus\"].to_numpy()\n",
    "genus_xtest, genus_ytest = sc_xtest, test_set[\"Genus\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "Results:\n",
      "{'C': 0.1, 'gamma': 0.1}  gives mean test score of  0.9473538937595436\n",
      "{'C': 0.1, 'gamma': 0.2}  gives mean test score of  0.9054456471657776\n",
      "{'C': 0.1, 'gamma': 0.30000000000000004}  gives mean test score of  0.8606419280251396\n",
      "{'C': 0.1, 'gamma': 0.4}  gives mean test score of  0.8172532232731872\n",
      "{'C': 0.1, 'gamma': 0.5}  gives mean test score of  0.7731646565373423\n",
      "{'C': 0.1, 'gamma': 0.6}  gives mean test score of  0.7291387642473826\n",
      "{'C': 0.1, 'gamma': 0.7000000000000001}  gives mean test score of  0.6815805738645466\n",
      "{'C': 0.1, 'gamma': 0.8}  gives mean test score of  0.651964648585581\n",
      "{'C': 0.1, 'gamma': 0.9}  gives mean test score of  0.6359519397343095\n",
      "{'C': 0.1, 'gamma': 1.0}  gives mean test score of  0.624761976431642\n",
      "{'C': 1, 'gamma': 0.1}  gives mean test score of  0.9847762701109788\n",
      "{'C': 1, 'gamma': 0.2}  gives mean test score of  0.9754274317369841\n",
      "{'C': 1, 'gamma': 0.30000000000000004}  gives mean test score of  0.9652411834896226\n",
      "{'C': 1, 'gamma': 0.4}  gives mean test score of  0.95641760561415\n",
      "{'C': 1, 'gamma': 0.5}  gives mean test score of  0.9321861459717695\n",
      "{'C': 1, 'gamma': 0.6}  gives mean test score of  0.9134398696004729\n",
      "{'C': 1, 'gamma': 0.7000000000000001}  gives mean test score of  0.8933329754065744\n",
      "{'C': 1, 'gamma': 0.8}  gives mean test score of  0.8724905414089867\n",
      "{'C': 1, 'gamma': 0.9}  gives mean test score of  0.8545089931837497\n",
      "{'C': 1, 'gamma': 1.0}  gives mean test score of  0.8328916231747879\n",
      "{'C': 10, 'gamma': 0.1}  gives mean test score of  0.9866555160857539\n",
      "{'C': 10, 'gamma': 0.2}  gives mean test score of  0.9777599048351521\n",
      "{'C': 10, 'gamma': 0.30000000000000004}  gives mean test score of  0.9684988873018929\n",
      "{'C': 10, 'gamma': 0.4}  gives mean test score of  0.9600144510820965\n",
      "{'C': 10, 'gamma': 0.5}  gives mean test score of  0.9383691404243066\n",
      "{'C': 10, 'gamma': 0.6}  gives mean test score of  0.9215012987072224\n",
      "{'C': 10, 'gamma': 0.7000000000000001}  gives mean test score of  0.9018216793423199\n",
      "{'C': 10, 'gamma': 0.8}  gives mean test score of  0.8832783894346476\n",
      "{'C': 10, 'gamma': 0.9}  gives mean test score of  0.8685090103781686\n",
      "{'C': 10, 'gamma': 1.0}  gives mean test score of  0.8484258173364925\n",
      "{'C': 100, 'gamma': 0.1}  gives mean test score of  0.9866555160857539\n",
      "{'C': 100, 'gamma': 0.2}  gives mean test score of  0.9777599048351521\n",
      "{'C': 100, 'gamma': 0.30000000000000004}  gives mean test score of  0.9684988873018929\n",
      "{'C': 100, 'gamma': 0.4}  gives mean test score of  0.9600144510820965\n",
      "{'C': 100, 'gamma': 0.5}  gives mean test score of  0.9383691404243066\n",
      "{'C': 100, 'gamma': 0.6}  gives mean test score of  0.9215012987072224\n",
      "{'C': 100, 'gamma': 0.7000000000000001}  gives mean test score of  0.9018216793423199\n",
      "{'C': 100, 'gamma': 0.8}  gives mean test score of  0.8832783894346476\n",
      "{'C': 100, 'gamma': 0.9}  gives mean test score of  0.8685090103781686\n",
      "{'C': 100, 'gamma': 1.0}  gives mean test score of  0.8484258173364925\n",
      "{'C': 1000, 'gamma': 0.1}  gives mean test score of  0.9866555160857539\n",
      "{'C': 1000, 'gamma': 0.2}  gives mean test score of  0.9777599048351521\n",
      "{'C': 1000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9684988873018929\n",
      "{'C': 1000, 'gamma': 0.4}  gives mean test score of  0.9600144510820965\n",
      "{'C': 1000, 'gamma': 0.5}  gives mean test score of  0.9383691404243066\n",
      "{'C': 1000, 'gamma': 0.6}  gives mean test score of  0.9215012987072224\n",
      "{'C': 1000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9018216793423199\n",
      "{'C': 1000, 'gamma': 0.8}  gives mean test score of  0.8832783894346476\n",
      "{'C': 1000, 'gamma': 0.9}  gives mean test score of  0.8685090103781686\n",
      "{'C': 1000, 'gamma': 1.0}  gives mean test score of  0.8484258173364925\n",
      "{'C': 10000, 'gamma': 0.1}  gives mean test score of  0.9866555160857539\n",
      "{'C': 10000, 'gamma': 0.2}  gives mean test score of  0.9777599048351521\n",
      "{'C': 10000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9684988873018929\n",
      "{'C': 10000, 'gamma': 0.4}  gives mean test score of  0.9600144510820965\n",
      "{'C': 10000, 'gamma': 0.5}  gives mean test score of  0.9383691404243066\n",
      "{'C': 10000, 'gamma': 0.6}  gives mean test score of  0.9215012987072224\n",
      "{'C': 10000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9018216793423199\n",
      "{'C': 10000, 'gamma': 0.8}  gives mean test score of  0.8832783894346476\n",
      "{'C': 10000, 'gamma': 0.9}  gives mean test score of  0.8685090103781686\n",
      "{'C': 10000, 'gamma': 1.0}  gives mean test score of  0.8484258173364925\n",
      "{'C': 100000, 'gamma': 0.1}  gives mean test score of  0.9866555160857539\n",
      "{'C': 100000, 'gamma': 0.2}  gives mean test score of  0.9777599048351521\n",
      "{'C': 100000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9684988873018929\n",
      "{'C': 100000, 'gamma': 0.4}  gives mean test score of  0.9600144510820965\n",
      "{'C': 100000, 'gamma': 0.5}  gives mean test score of  0.9383691404243066\n",
      "{'C': 100000, 'gamma': 0.6}  gives mean test score of  0.9215012987072224\n",
      "{'C': 100000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9018216793423199\n",
      "{'C': 100000, 'gamma': 0.8}  gives mean test score of  0.8832783894346476\n",
      "{'C': 100000, 'gamma': 0.9}  gives mean test score of  0.8685090103781686\n",
      "{'C': 100000, 'gamma': 1.0}  gives mean test score of  0.8484258173364925\n",
      "{'C': 1000000, 'gamma': 0.1}  gives mean test score of  0.9866555160857539\n",
      "{'C': 1000000, 'gamma': 0.2}  gives mean test score of  0.9777599048351521\n",
      "{'C': 1000000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9684988873018929\n",
      "{'C': 1000000, 'gamma': 0.4}  gives mean test score of  0.9600144510820965\n",
      "{'C': 1000000, 'gamma': 0.5}  gives mean test score of  0.9383691404243066\n",
      "{'C': 1000000, 'gamma': 0.6}  gives mean test score of  0.9215012987072224\n",
      "{'C': 1000000, 'gamma': 0.7000000000000001}  gives mean test score of  0.9018216793423199\n",
      "{'C': 1000000, 'gamma': 0.8}  gives mean test score of  0.8832783894346476\n",
      "{'C': 1000000, 'gamma': 0.9}  gives mean test score of  0.8685090103781686\n",
      "{'C': 1000000, 'gamma': 1.0}  gives mean test score of  0.8484258173364925\n",
      "Best score is  0.9866555160857539  for parameters  {'C': 10, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-1,7)]\n",
    "gamma_list = np.arange(0.1,1.1,0.1)\n",
    "params = {\"C\":C_list,\"gamma\":gamma_list}\n",
    "\n",
    "estimator = svm.SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "clf = best_params(genus_xtrain,genus_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_pred = clf.predict(genus_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_xtrain, species_ytrain = sc_xtrain, train_set[\"Species\"].to_numpy()\n",
    "species_xtest, species_ytest = sc_xtest, test_set[\"Species\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "Results:\n",
      "{'C': 0.1, 'gamma': 0.1}  gives mean test score of  0.9560529032059986\n",
      "{'C': 0.1, 'gamma': 0.2}  gives mean test score of  0.9207817082510765\n",
      "{'C': 0.1, 'gamma': 0.30000000000000004}  gives mean test score of  0.8665131992664392\n",
      "{'C': 0.1, 'gamma': 0.4}  gives mean test score of  0.804131055493175\n",
      "{'C': 0.1, 'gamma': 0.5}  gives mean test score of  0.73785799328791\n",
      "{'C': 0.1, 'gamma': 0.6}  gives mean test score of  0.6739442593011596\n",
      "{'C': 0.1, 'gamma': 0.7000000000000001}  gives mean test score of  0.6154655770715121\n",
      "{'C': 0.1, 'gamma': 0.8}  gives mean test score of  0.5753511910120397\n",
      "{'C': 0.1, 'gamma': 0.9}  gives mean test score of  0.5507665958046895\n",
      "{'C': 0.1, 'gamma': 1.0}  gives mean test score of  0.5295910465650484\n",
      "{'C': 1, 'gamma': 0.1}  gives mean test score of  0.9827154924722235\n",
      "{'C': 1, 'gamma': 0.2}  gives mean test score of  0.9723286262503574\n",
      "{'C': 1, 'gamma': 0.30000000000000004}  gives mean test score of  0.96541343779309\n",
      "{'C': 1, 'gamma': 0.4}  gives mean test score of  0.9445262445430893\n",
      "{'C': 1, 'gamma': 0.5}  gives mean test score of  0.9266560803075427\n",
      "{'C': 1, 'gamma': 0.6}  gives mean test score of  0.9065530938888404\n",
      "{'C': 1, 'gamma': 0.7000000000000001}  gives mean test score of  0.8840003019720214\n",
      "{'C': 1, 'gamma': 0.8}  gives mean test score of  0.859880133285013\n",
      "{'C': 1, 'gamma': 0.9}  gives mean test score of  0.8346924405768638\n",
      "{'C': 1, 'gamma': 1.0}  gives mean test score of  0.8108391970232445\n",
      "{'C': 10, 'gamma': 0.1}  gives mean test score of  0.9845892447343015\n",
      "{'C': 10, 'gamma': 0.2}  gives mean test score of  0.975115005801286\n",
      "{'C': 10, 'gamma': 0.30000000000000004}  gives mean test score of  0.9661757122693523\n",
      "{'C': 10, 'gamma': 0.4}  gives mean test score of  0.9481337831304492\n",
      "{'C': 10, 'gamma': 0.5}  gives mean test score of  0.93233983005094\n",
      "{'C': 10, 'gamma': 0.6}  gives mean test score of  0.9133402599821372\n",
      "{'C': 10, 'gamma': 0.7000000000000001}  gives mean test score of  0.8934680967704495\n",
      "{'C': 10, 'gamma': 0.8}  gives mean test score of  0.8742105564209426\n",
      "{'C': 10, 'gamma': 0.9}  gives mean test score of  0.8517370989583976\n",
      "{'C': 10, 'gamma': 1.0}  gives mean test score of  0.8289860865517495\n",
      "{'C': 100, 'gamma': 0.1}  gives mean test score of  0.9845892447343015\n",
      "{'C': 100, 'gamma': 0.2}  gives mean test score of  0.975115005801286\n",
      "{'C': 100, 'gamma': 0.30000000000000004}  gives mean test score of  0.9661757122693523\n",
      "{'C': 100, 'gamma': 0.4}  gives mean test score of  0.9481337831304492\n",
      "{'C': 100, 'gamma': 0.5}  gives mean test score of  0.93233983005094\n",
      "{'C': 100, 'gamma': 0.6}  gives mean test score of  0.9133402599821372\n",
      "{'C': 100, 'gamma': 0.7000000000000001}  gives mean test score of  0.8934680967704495\n",
      "{'C': 100, 'gamma': 0.8}  gives mean test score of  0.8742105564209426\n",
      "{'C': 100, 'gamma': 0.9}  gives mean test score of  0.8517370989583976\n",
      "{'C': 100, 'gamma': 1.0}  gives mean test score of  0.8289860865517495\n",
      "{'C': 1000, 'gamma': 0.1}  gives mean test score of  0.9845892447343015\n",
      "{'C': 1000, 'gamma': 0.2}  gives mean test score of  0.975115005801286\n",
      "{'C': 1000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9661757122693523\n",
      "{'C': 1000, 'gamma': 0.4}  gives mean test score of  0.9481337831304492\n",
      "{'C': 1000, 'gamma': 0.5}  gives mean test score of  0.93233983005094\n",
      "{'C': 1000, 'gamma': 0.6}  gives mean test score of  0.9133402599821372\n",
      "{'C': 1000, 'gamma': 0.7000000000000001}  gives mean test score of  0.8934680967704495\n",
      "{'C': 1000, 'gamma': 0.8}  gives mean test score of  0.8742105564209426\n",
      "{'C': 1000, 'gamma': 0.9}  gives mean test score of  0.8517370989583976\n",
      "{'C': 1000, 'gamma': 1.0}  gives mean test score of  0.8289860865517495\n",
      "{'C': 10000, 'gamma': 0.1}  gives mean test score of  0.9845892447343015\n",
      "{'C': 10000, 'gamma': 0.2}  gives mean test score of  0.975115005801286\n",
      "{'C': 10000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9661757122693523\n",
      "{'C': 10000, 'gamma': 0.4}  gives mean test score of  0.9481337831304492\n",
      "{'C': 10000, 'gamma': 0.5}  gives mean test score of  0.93233983005094\n",
      "{'C': 10000, 'gamma': 0.6}  gives mean test score of  0.9133402599821372\n",
      "{'C': 10000, 'gamma': 0.7000000000000001}  gives mean test score of  0.8934680967704495\n",
      "{'C': 10000, 'gamma': 0.8}  gives mean test score of  0.8742105564209426\n",
      "{'C': 10000, 'gamma': 0.9}  gives mean test score of  0.8517370989583976\n",
      "{'C': 10000, 'gamma': 1.0}  gives mean test score of  0.8289860865517495\n",
      "{'C': 100000, 'gamma': 0.1}  gives mean test score of  0.9845892447343015\n",
      "{'C': 100000, 'gamma': 0.2}  gives mean test score of  0.975115005801286\n",
      "{'C': 100000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9661757122693523\n",
      "{'C': 100000, 'gamma': 0.4}  gives mean test score of  0.9481337831304492\n",
      "{'C': 100000, 'gamma': 0.5}  gives mean test score of  0.93233983005094\n",
      "{'C': 100000, 'gamma': 0.6}  gives mean test score of  0.9133402599821372\n",
      "{'C': 100000, 'gamma': 0.7000000000000001}  gives mean test score of  0.8934680967704495\n",
      "{'C': 100000, 'gamma': 0.8}  gives mean test score of  0.8742105564209426\n",
      "{'C': 100000, 'gamma': 0.9}  gives mean test score of  0.8517370989583976\n",
      "{'C': 100000, 'gamma': 1.0}  gives mean test score of  0.8289860865517495\n",
      "{'C': 1000000, 'gamma': 0.1}  gives mean test score of  0.9845892447343015\n",
      "{'C': 1000000, 'gamma': 0.2}  gives mean test score of  0.975115005801286\n",
      "{'C': 1000000, 'gamma': 0.30000000000000004}  gives mean test score of  0.9661757122693523\n",
      "{'C': 1000000, 'gamma': 0.4}  gives mean test score of  0.9481337831304492\n",
      "{'C': 1000000, 'gamma': 0.5}  gives mean test score of  0.93233983005094\n",
      "{'C': 1000000, 'gamma': 0.6}  gives mean test score of  0.9133402599821372\n",
      "{'C': 1000000, 'gamma': 0.7000000000000001}  gives mean test score of  0.8934680967704495\n",
      "{'C': 1000000, 'gamma': 0.8}  gives mean test score of  0.8742105564209426\n",
      "{'C': 1000000, 'gamma': 0.9}  gives mean test score of  0.8517370989583976\n",
      "{'C': 1000000, 'gamma': 1.0}  gives mean test score of  0.8289860865517495\n",
      "Best score is  0.9845892447343015  for parameters  {'C': 10, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-1,7)]\n",
    "gamma_list = np.arange(0.1,1.1,0.1)\n",
    "params = {\"C\":C_list,\"gamma\":gamma_list}\n",
    "\n",
    "estimator = svm.SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "clf = best_params(species_xtrain,species_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_pred = clf.predict(species_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_pred = np.array([family_pred,genus_pred,species_pred]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss:  0.011733827389223406\n",
      "Exact Match Ratio:  0.983788791106994\n"
     ]
    }
   ],
   "source": [
    "summary_dict[\"SVM_Gaussian_std\"] = eval_model(y_multi_true,y_multi_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (b) iii. Repeat 1(b)ii with L1-penalized SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_set.iloc[:,:-3])\n",
    "\n",
    "sc_xtrain = scaler.transform(train_set.iloc[:,:-3])\n",
    "sc_xtest = scaler.transform(test_set.iloc[:,:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Family Label\n",
    "\n",
    "family_xtrain, family_ytrain = sc_xtrain, train_set[\"Family\"].to_numpy()\n",
    "family_xtest, family_ytest = sc_xtest, test_set[\"Family\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LibLinear]Results:\n",
      "{'C': 0.001}  gives mean test score of  0.8228733949753286\n",
      "{'C': 0.01}  gives mean test score of  0.9265293311275651\n",
      "{'C': 0.1}  gives mean test score of  0.9340622181757438\n",
      "{'C': 1}  gives mean test score of  0.9368967217762026\n",
      "{'C': 10}  gives mean test score of  0.9373835037156646\n",
      "{'C': 100}  gives mean test score of  0.9371808706425874\n",
      "{'C': 1000}  gives mean test score of  0.9371808706425874\n",
      "{'C': 10000}  gives mean test score of  0.9371808706425874\n",
      "{'C': 100000}  gives mean test score of  0.9371808706425874\n",
      "{'C': 1000000}  gives mean test score of  0.9371808706425874\n",
      "Best score is  0.9373835037156646  for parameters  {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-3,7)]\n",
    "\n",
    "params = {\"C\":C_list}\n",
    "\n",
    "estimator = svm.LinearSVC(penalty=\"l1\", dual=False, verbose=1)\n",
    "\n",
    "clf = best_params(family_xtrain,family_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_pred = clf.predict(family_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genus Label\n",
    "\n",
    "genus_xtrain, genus_ytrain = sc_xtrain, train_set[\"Genus\"].to_numpy()\n",
    "genus_xtest, genus_ytest = sc_xtest, test_set[\"Genus\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LibLinear]Results:\n",
      "{'C': 0.001}  gives mean test score of  0.770115180413346\n",
      "{'C': 0.01}  gives mean test score of  0.8935414027200412\n",
      "{'C': 0.1}  gives mean test score of  0.9336781445758738\n",
      "{'C': 1}  gives mean test score of  0.9449990142972574\n",
      "{'C': 10}  gives mean test score of  0.9472039596183117\n",
      "{'C': 100}  gives mean test score of  0.9472427696120382\n",
      "{'C': 1000}  gives mean test score of  0.9474892972001158\n",
      "{'C': 10000}  gives mean test score of  0.9474892972001158\n",
      "{'C': 100000}  gives mean test score of  0.9474892972001158\n",
      "{'C': 1000000}  gives mean test score of  0.9474892972001158\n",
      "Best score is  0.9474892972001158  for parameters  {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-3,7)]\n",
    "\n",
    "params = {\"C\":C_list}\n",
    "\n",
    "estimator = svm.LinearSVC(penalty=\"l1\", dual=False, verbose=1)\n",
    "\n",
    "clf = best_params(genus_xtrain,genus_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_pred = clf.predict(genus_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Species Label\n",
    "\n",
    "species_xtrain, species_ytrain = sc_xtrain, train_set[\"Species\"].to_numpy()\n",
    "species_xtest, species_ytest = sc_xtest, test_set[\"Species\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LibLinear]Results:\n",
      "{'C': 0.001}  gives mean test score of  0.7309206369190463\n",
      "{'C': 0.01}  gives mean test score of  0.8968970195368582\n",
      "{'C': 0.1}  gives mean test score of  0.9454963140717639\n",
      "{'C': 1}  gives mean test score of  0.9584510960306802\n",
      "{'C': 10}  gives mean test score of  0.9589722439814052\n",
      "{'C': 100}  gives mean test score of  0.9589681719300496\n",
      "{'C': 1000}  gives mean test score of  0.9587872731346753\n",
      "{'C': 10000}  gives mean test score of  0.9589681719300496\n",
      "{'C': 100000}  gives mean test score of  0.9589681719300496\n",
      "{'C': 1000000}  gives mean test score of  0.9589759158966917\n",
      "Best score is  0.9589759158966917  for parameters  {'C': 1000000}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-3,7)]\n",
    "\n",
    "params = {\"C\":C_list}\n",
    "\n",
    "estimator = svm.LinearSVC(penalty=\"l1\", dual=False, verbose=1)\n",
    "\n",
    "clf = best_params(species_xtrain,species_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_pred = clf.predict(species_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_pred = np.array([family_pred,genus_pred,species_pred]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss:  0.05697081982399259\n",
      "Exact Match Ratio:  0.9124594719777674\n"
     ]
    }
   ],
   "source": [
    "summary_dict[\"l1_svm\"] = eval_model(y_multi_true,y_multi_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (b) iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LibLinear]Results:\n",
      "{'l1svm__C': 0.001}  gives mean test score of  0.854702099709024\n",
      "{'l1svm__C': 0.01}  gives mean test score of  0.9061892857330488\n",
      "{'l1svm__C': 0.1}  gives mean test score of  0.926525143075347\n",
      "{'l1svm__C': 1}  gives mean test score of  0.9282154950672223\n",
      "{'l1svm__C': 10}  gives mean test score of  0.9276708688349837\n",
      "{'l1svm__C': 100}  gives mean test score of  0.9278875430122449\n",
      "{'l1svm__C': 1000}  gives mean test score of  0.9298941619560743\n",
      "{'l1svm__C': 10000}  gives mean test score of  0.9293225752819823\n",
      "{'l1svm__C': 100000}  gives mean test score of  0.9274696551482486\n",
      "{'l1svm__C': 1000000}  gives mean test score of  0.9276949306358275\n",
      "Best score is  0.9298941619560743  for parameters  {'l1svm__C': 1000}\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/35632634/how-to-pass-a-parameter-to-only-one-part-of-a-pipeline-object-in-scikit-learn\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-3,7)]\n",
    "\n",
    "params = {\"l1svm__C\":C_list}\n",
    "\n",
    "estimator = Pipeline([('smote', SMOTE()), ('l1svm', svm.LinearSVC(penalty=\"l1\", dual=False, verbose=1))])\n",
    "\n",
    "clf = best_params(family_xtrain,family_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_pred = clf.predict(family_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LibLinear]Results:\n",
      "{'l1svm__C': 0.001}  gives mean test score of  0.885969383236991\n",
      "{'l1svm__C': 0.01}  gives mean test score of  0.9091759525357885\n",
      "{'l1svm__C': 0.1}  gives mean test score of  0.9209599628272731\n",
      "{'l1svm__C': 1}  gives mean test score of  0.9210247598513929\n",
      "{'l1svm__C': 10}  gives mean test score of  0.9202556803968867\n",
      "{'l1svm__C': 100}  gives mean test score of  0.922144622447026\n",
      "{'l1svm__C': 1000}  gives mean test score of  0.9216432248976529\n",
      "{'l1svm__C': 10000}  gives mean test score of  0.922043532077985\n",
      "{'l1svm__C': 100000}  gives mean test score of  0.9214970311099393\n",
      "{'l1svm__C': 1000000}  gives mean test score of  0.9196431839587763\n",
      "Best score is  0.922144622447026  for parameters  {'l1svm__C': 100}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-3,7)]\n",
    "\n",
    "params = {\"l1svm__C\":C_list}\n",
    "\n",
    "estimator = Pipeline([('smote', SMOTE()), ('l1svm', svm.LinearSVC(penalty=\"l1\", dual=False, verbose=1))])\n",
    "\n",
    "clf = best_params(genus_xtrain,genus_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_pred = clf.predict(genus_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LibLinear]Results:\n",
      "{'l1svm__C': 0.001}  gives mean test score of  0.9313761290334988\n",
      "{'l1svm__C': 0.01}  gives mean test score of  0.9532767026297838\n",
      "{'l1svm__C': 0.1}  gives mean test score of  0.9578066343446643\n",
      "{'l1svm__C': 1}  gives mean test score of  0.9563405759201347\n",
      "{'l1svm__C': 10}  gives mean test score of  0.9579226627695172\n",
      "{'l1svm__C': 100}  gives mean test score of  0.9585685382129002\n",
      "{'l1svm__C': 1000}  gives mean test score of  0.9584064220252273\n",
      "{'l1svm__C': 10000}  gives mean test score of  0.9584679111441714\n",
      "{'l1svm__C': 100000}  gives mean test score of  0.9579700981694474\n",
      "{'l1svm__C': 1000000}  gives mean test score of  0.9582735020776953\n",
      "Best score is  0.9585685382129002  for parameters  {'l1svm__C': 100}\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "C_list = [10**i for i in range(-3,7)]\n",
    "\n",
    "params = {\"l1svm__C\":C_list}\n",
    "\n",
    "estimator = Pipeline([('smote', SMOTE()), ('l1svm', svm.LinearSVC(penalty=\"l1\", dual=False, verbose=1))])\n",
    "\n",
    "clf = best_params(species_xtrain,species_ytrain,params=params,estimator=estimator,scoring=\"f1_weighted\",cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_pred = clf.predict(species_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_pred = np.array([family_pred,genus_pred,species_pred]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss:  0.07626987802995214\n",
      "Exact Match Ratio:  0.8559518295507179\n"
     ]
    }
   ],
   "source": [
    "summary_dict[\"l1_svm_smote\"] = eval_model(y_multi_true,y_multi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Hamming loss</th>\n",
       "      <th>Exact match ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_Gaussian_no_std</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.986105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_Gaussian_std</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.983789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1_svm</td>\n",
       "      <td>0.056971</td>\n",
       "      <td>0.912459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1_svm_smote</td>\n",
       "      <td>0.076270</td>\n",
       "      <td>0.855952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Hamming loss  Exact match ratio\n",
       "0  SVM_Gaussian_no_std      0.008492           0.986105\n",
       "1     SVM_Gaussian_std      0.011734           0.983789\n",
       "2               l1_svm      0.056971           0.912459\n",
       "3         l1_svm_smote      0.076270           0.855952"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns=[\"Model\",\"Hamming loss\",\"Exact match ratio\"])\n",
    "df_idx = 0\n",
    "\n",
    "for model in summary_dict.keys():\n",
    "    summary_df.loc[df_idx] = [model, summary_dict[model][\"hamming_loss\"], summary_dict[model][\"exact_match_ratio\"]]\n",
    "    df_idx+=1\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024017</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083536</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.554504</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.443451</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.021860</td>\n",
       "      <td>-0.079860</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517273</td>\n",
       "      <td>-0.370574</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.402890</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.101892</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.582557</td>\n",
       "      <td>-0.343237</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.385596</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.080425</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.519497</td>\n",
       "      <td>-0.307553</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>-0.096895</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508833</td>\n",
       "      <td>-0.324106</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>0.058874</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>0.072983</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.087910</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1          1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2          1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3          1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4          1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7190       1.0 -0.554504 -0.337717  0.035533  0.034511  0.443451  0.093889   \n",
       "7191       1.0 -0.517273 -0.370574  0.030673  0.068097  0.402890  0.096628   \n",
       "7192       1.0 -0.582557 -0.343237  0.029468  0.064179  0.385596  0.114905   \n",
       "7193       1.0 -0.519497 -0.307553 -0.004922  0.072865  0.377131  0.086866   \n",
       "7194       1.0 -0.508833 -0.324106  0.062068  0.078211  0.397188  0.094596   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_16  MFCCs_17  MFCCs_18  \\\n",
       "0    -0.150063 -0.171128  0.124676  ... -0.024017 -0.108351 -0.077623   \n",
       "1    -0.222475 -0.207693  0.170883  ...  0.012022 -0.090974 -0.056510   \n",
       "2    -0.242234 -0.219153  0.232538  ...  0.083536 -0.050691 -0.023590   \n",
       "3    -0.194347 -0.098181  0.270375  ... -0.050224 -0.136009 -0.177037   \n",
       "4    -0.265423 -0.172700  0.266434  ...  0.062837 -0.048885 -0.053074   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7190 -0.100753  0.037087  0.081075  ... -0.000861  0.069430  0.071001   \n",
       "7191 -0.116460  0.063727  0.089034  ...  0.006457  0.061127  0.068978   \n",
       "7192 -0.103317  0.070370  0.081317  ...  0.008696  0.082474  0.077771   \n",
       "7193 -0.115799  0.056979  0.089316  ...  0.001924  0.051796  0.069073   \n",
       "7194 -0.117672  0.058874  0.076180  ...  0.004158  0.061455  0.072983   \n",
       "\n",
       "      MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus  \\\n",
       "0    -0.009568  0.057684  0.118680  0.014038  Leptodactylidae  Adenomera   \n",
       "1    -0.035303  0.020140  0.082263  0.029056  Leptodactylidae  Adenomera   \n",
       "2    -0.066722 -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera   \n",
       "3    -0.130498 -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera   \n",
       "4    -0.088550 -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera   \n",
       "...        ...       ...       ...       ...              ...        ...   \n",
       "7190  0.021591  0.052449 -0.021860 -0.079860          Hylidae     Scinax   \n",
       "7191  0.017745  0.046461 -0.015418 -0.101892          Hylidae     Scinax   \n",
       "7192 -0.009688  0.027834 -0.000531 -0.080425          Hylidae     Scinax   \n",
       "7193  0.017963  0.041803 -0.027911 -0.096895          Hylidae     Scinax   \n",
       "7194 -0.003980  0.031560 -0.029355 -0.087910          Hylidae     Scinax   \n",
       "\n",
       "             Species  \n",
       "0     AdenomeraAndre  \n",
       "1     AdenomeraAndre  \n",
       "2     AdenomeraAndre  \n",
       "3     AdenomeraAndre  \n",
       "4     AdenomeraAndre  \n",
       "...              ...  \n",
       "7190     ScinaxRuber  \n",
       "7191     ScinaxRuber  \n",
       "7192     ScinaxRuber  \n",
       "7193     ScinaxRuber  \n",
       "7194     ScinaxRuber  \n",
       "\n",
       "[7195 rows x 25 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Frogs_MFCCs.csv\")\n",
    "del df[\"RecordID\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb\n",
    "\n",
    "def optimalk(x,seed):\n",
    "    max_score = -1\n",
    "    best_k = 0\n",
    "    for k in range(2, 51):\n",
    "        kmeans = KMeans(n_clusters = k, random_state=seed).fit(x)\n",
    "        labels = kmeans.labels_\n",
    "        silhouette_sc = silhouette_score(x, labels, metric = 'euclidean')\n",
    "        \n",
    "        if silhouette_sc > max_score:\n",
    "            max_score = silhouette_sc\n",
    "            best_k = k\n",
    "    return best_k\n",
    "\n",
    "def hamming_metrics(best_k,y_true,y_label):\n",
    "    y_temp = y_true.copy()\n",
    "    y_temp[\"label\"] = y_label\n",
    "    \n",
    "    dist = 0\n",
    "    for k in range(best_k):\n",
    "        y_cluster = y_temp[y_temp[\"label\"]==k]\n",
    "        family_label = y_cluster[\"Family\"].value_counts().sort_values(ascending=False).keys().tolist()[0]\n",
    "        genus_label = y_cluster[\"Genus\"].value_counts().sort_values(ascending=False).keys().tolist()[0]\n",
    "        species_label = y_cluster[\"Species\"].value_counts().sort_values(ascending=False).keys().tolist()[0]\n",
    "        majority_label = [family_label,genus_label,species_label]\n",
    "\n",
    "        for i in range(y_cluster.shape[0]):\n",
    "            for j in range(y_cluster.shape[1]-1):\n",
    "                if y_cluster.iloc[i,j] != majority_label[j]:\n",
    "                    dist+=1\n",
    "    hamming_distance = dist/y_true.shape[0]\n",
    "    hamming_loss = (1/(y_true.shape[0]*y_true.shape[1]))*dist\n",
    "    \n",
    "    return hamming_loss, hamming_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo Simulation  1\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  2\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.23405142460041695  Hamming distance: 0.7021542738012508\n",
      "\n",
      "Monte Carlo Simulation  3\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  4\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  5\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  6\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.2800092656937688  Hamming distance: 0.8400277970813065\n",
      "\n",
      "Monte Carlo Simulation  7\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.2800092656937688  Hamming distance: 0.8400277970813065\n",
      "\n",
      "Monte Carlo Simulation  8\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  9\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  10\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22214500810748206  Hamming distance: 0.6664350243224462\n",
      "\n",
      "Monte Carlo Simulation  11\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.24512392865415797  Hamming distance: 0.735371785962474\n",
      "\n",
      "Monte Carlo Simulation  12\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22246930738939077  Hamming distance: 0.6674079221681724\n",
      "\n",
      "Monte Carlo Simulation  13\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.23405142460041695  Hamming distance: 0.7021542738012508\n",
      "\n",
      "Monte Carlo Simulation  14\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  15\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  16\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  17\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  18\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  19\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  20\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  21\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  22\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  23\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22228399351401434  Hamming distance: 0.6668519805420431\n",
      "\n",
      "Monte Carlo Simulation  24\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  25\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.2217743803567292  Hamming distance: 0.6653231410701876\n",
      "\n",
      "Monte Carlo Simulation  26\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  27\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  28\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  29\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22246930738939077  Hamming distance: 0.6674079221681724\n",
      "\n",
      "Monte Carlo Simulation  30\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22228399351401434  Hamming distance: 0.6668519805420431\n",
      "\n",
      "Monte Carlo Simulation  31\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  32\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  33\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  34\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  35\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22246930738939077  Hamming distance: 0.6674079221681724\n",
      "\n",
      "Monte Carlo Simulation  36\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.24512392865415797  Hamming distance: 0.735371785962474\n",
      "\n",
      "Monte Carlo Simulation  37\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  38\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.23363446838082  Hamming distance: 0.7009034051424601\n",
      "\n",
      "Monte Carlo Simulation  39\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.24512392865415797  Hamming distance: 0.735371785962474\n",
      "\n",
      "Monte Carlo Simulation  40\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  41\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  42\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  43\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  44\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  45\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  46\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  47\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22228399351401434  Hamming distance: 0.6668519805420431\n",
      "\n",
      "Monte Carlo Simulation  48\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  49\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.22242297892054666  Hamming distance: 0.66726893676164\n",
      "\n",
      "Monte Carlo Simulation  50\n",
      "Optimal k : 4\n",
      "Hamming loss: 0.23400509613157286  Hamming distance: 0.7020152883947186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hamming_losses=[]\n",
    "hamming_distances=[]\n",
    "for m in range(50):\n",
    "    print(\"Monte Carlo Simulation \",m+1)\n",
    "    best_k = optimalk(df.iloc[:,:-3],(m+1)*10)\n",
    "    \n",
    "    print(\"Optimal k :\",best_k)\n",
    "    kmeans = KMeans(n_clusters=best_k,random_state=(m+1)*10)\n",
    "    kmeans.fit(df.iloc[:,:-3])\n",
    "\n",
    "    y_label = kmeans.labels_\n",
    "    hamming_loss, hamming_distance = hamming_metrics(best_k,df.iloc[:,-3:],y_label)\n",
    "    print(\"Hamming loss:\",hamming_loss,\" Hamming distance:\",hamming_distance)\n",
    "    print()\n",
    "    hamming_losses.append(hamming_loss)\n",
    "    hamming_distances.append(hamming_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Hamming loss: 0.2269854065323141\n",
      "Standard deviation of Hamming loss: 0.012384199360472468\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Hamming loss:\",np.mean(hamming_losses))\n",
    "print(\"Standard deviation of Hamming loss:\",np.std(hamming_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Hamming distance: 0.6809562195969421\n",
      "Standard deviation of Hamming distance: 0.03715259808141741\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Hamming distance:\",np.mean(hamming_distances))\n",
    "print(\"Standard deviation of Hamming distance:\",np.std(hamming_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Hamming score: 0.7730145934676859\n",
      "Standard deviation of Hamming score: 0.012384199360472468\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Hamming score:\",1-np.mean(hamming_losses))\n",
    "print(\"Standard deviation of Hamming score:\",np.std(hamming_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 12.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Complete Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1lDIU0aAKtVT_NS6jg4lTWJTCQrpEgVTE\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Single linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1Eme-ppnwv30deYlH8AkjgieJxAQ_dsci\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Suppose that we cut the dendrogram obtained in (a) such that two clusters result. Which observations are in each cluster?\n",
    "\n",
    "Cluster 1 - 1,2\n",
    "\n",
    "Cluster 2 - 3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Suppose that we cut the dendrogram obtained in (b) such that two clusters result. Which observations are in each cluster?\n",
    "\n",
    "Cluster 1 - 1,2,3\n",
    "\n",
    "Cluster 2 - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Draw a dendrogram that is equivalent to the dendrogram in (a), for which two or more of the leaves are repositioned, but for which the meaning of the dendrogram is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1q9FogoVpJ1ooMVxYE7rDc8MFW_xlNlH-\" width=\"300\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
